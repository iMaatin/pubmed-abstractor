{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Requirements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from urllib.request import urlopen\n",
    "from urllib.error import HTTPError\n",
    "from urllib.error import URLError\n",
    "import xml.etree.cElementTree as et\n",
    "import xmltodict, json, os\n",
    "import pandas as pd\n",
    "from fpdf import FPDF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ESearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "api_key = \"b30c3c67620ea99cf640ccbfb01422554c08\"\n",
    "\n",
    "base_url = \"https://eutils.ncbi.nlm.nih.gov/entrez/eutils/esearch.fcgi?\"\n",
    "\n",
    "db = \"pubmed\"\n",
    "\n",
    "term = \"multiple+sclerosis[Title/Abstract]+AND+corpus+callosum[Title/Abstract]\"\n",
    "\n",
    "retmax = \"100000\"\n",
    "\n",
    "rettype = \"uilist\"\n",
    "\n",
    "url = base_url + \"db=\" + db + \"&term=\" + term + \"&retmax=\" + retmax + \"&rettype=\" + rettype + \"&usehistory=y\" + \"&api_key=\" + api_key\n",
    "\n",
    "try:\n",
    "    search_results = json.dumps(xmltodict.parse(urlopen(url).read().decode('utf-8')), indent = 4)\n",
    "    with open(\"pubmed_search_results.json\", \"w\") as output:\n",
    "        output.write(search_results)\n",
    "except HTTPError as e:\n",
    "    print(e)\n",
    "except URLError as e:\n",
    "    print('Not found!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set Query Key and Web Environment to use history later\n",
    "\n",
    "with open(\"pubmed_search_results.json\", \"r\") as search_results:\n",
    "    search_results = json.load(search_results)\n",
    "\n",
    "web_env = search_results[\"eSearchResult\"][\"WebEnv\"]\n",
    "query_key = search_results[\"eSearchResult\"][\"QueryKey\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### EFetch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_url = \"https://eutils.ncbi.nlm.nih.gov/entrez/eutils/efetch.fcgi?\"\n",
    "\n",
    "rettype = \"xml\"\n",
    "\n",
    "url = base_url + \"db=\" + db + \"&retmax=\" + retmax + \"&rettype=\" + rettype + \"&query_key=\" + query_key + \"&WebEnv=\" + web_env  + \"&api_key=\" + api_key\n",
    "\n",
    "try:\n",
    "    fetch_results = json.dumps(xmltodict.parse(urlopen(url).read().decode('utf-8')), indent = 4)\n",
    "    with open(\"pubmed_fetch_results.json\", \"w\") as output:\n",
    "        output.write(fetch_results)\n",
    "except HTTPError as e:\n",
    "    print(e)\n",
    "except URLError as e:\n",
    "    print('Not found!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Check this article manually. PMID: 27400790\n",
      "Check this article manually. PMID: 26338327\n",
      "Check this article manually. PMID: 26157006\n"
     ]
    }
   ],
   "source": [
    "with open(\"pubmed_fetch_results.json\", \"r\") as fetch_results:\n",
    "    fetch_results = json.load(fetch_results)\n",
    "\n",
    "IDs = [None] * len(fetch_results[\"PubmedArticleSet\"][\"PubmedArticle\"])\n",
    "titles = [None] * len(fetch_results[\"PubmedArticleSet\"][\"PubmedArticle\"])\n",
    "abstracts = [\"\"] * len(fetch_results[\"PubmedArticleSet\"][\"PubmedArticle\"])\n",
    "for index, article in enumerate(fetch_results[\"PubmedArticleSet\"][\"PubmedArticle\"]):\n",
    "    IDs[index] = article[\"MedlineCitation\"][\"PMID\"][\"#text\"]\n",
    "    titles[index] = article[\"MedlineCitation\"][\"Article\"][\"ArticleTitle\"]\n",
    "    if \"Abstract\" in article[\"MedlineCitation\"][\"Article\"]:\n",
    "        if isinstance(article[\"MedlineCitation\"][\"Article\"][\"Abstract\"][\"AbstractText\"], str):\n",
    "            IDs[index] = article[\"MedlineCitation\"][\"PMID\"][\"#text\"]\n",
    "            titles[index] = article[\"MedlineCitation\"][\"Article\"][\"ArticleTitle\"]\n",
    "            abstracts[index] = article[\"MedlineCitation\"][\"Article\"][\"Abstract\"][\"AbstractText\"]\n",
    "        elif isinstance(article[\"MedlineCitation\"][\"Article\"][\"Abstract\"][\"AbstractText\"], list):\n",
    "            abstract = \"\"\n",
    "            for item in article[\"MedlineCitation\"][\"Article\"][\"Abstract\"][\"AbstractText\"]:\n",
    "                if isinstance(item, dict):\n",
    "                    error = 0\n",
    "                    abstract += item[\"#text\"]\n",
    "                else:\n",
    "                    error = 2\n",
    "                    break\n",
    "            if error == 2:\n",
    "                print(f'Check this article manually. PMID: {article[\"MedlineCitation\"][\"PMID\"][\"#text\"]}')\n",
    "                abstracts[index] = \"No abstract\"\n",
    "            else:\n",
    "                abstracts[index] += abstract\n",
    "        elif isinstance(article[\"MedlineCitation\"][\"Article\"][\"Abstract\"][\"AbstractText\"], dict):\n",
    "            abstracts[index] = article[\"MedlineCitation\"][\"Article\"][\"Abstract\"][\"AbstractText\"][\"#text\"]\n",
    "    else:\n",
    "        abstracts[index] = \"No abstract\"\n",
    "\n",
    "articles_list = {'ID': IDs, 'Title': titles, 'Abstract': abstracts}\n",
    "articles_list = pd.DataFrame(articles_list)\n",
    "articles_list.to_csv(\"pubmed_articles.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create PDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "''"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fonts = os.listdir(\"fonts/\")\n",
    "for file in fonts:\n",
    "    if file.endswith(\".pkl\"):\n",
    "        os.remove(os.path.join(\"fonts/\", file))\n",
    "\n",
    "pdf = FPDF()\n",
    "pdf.add_font('Roboto', style = \"\", fname = os.path.abspath(\"fonts/Roboto-Regular.ttf\"), uni = True)\n",
    "pdf.add_font('Roboto', style = \"B\", fname = os.path.abspath(\"fonts/Roboto-Bold.ttf\"), uni = True)\n",
    "pdf.set_margins(left = 20, top = 20, right = 20)\n",
    "\n",
    "for article_number in range(1, len(IDs)):\n",
    "\n",
    "    pdf.add_page()\n",
    "    pdf.set_text_color(r = 41, g = 128, b = 185)\n",
    "    pdf.set_font('Roboto', '', 10)\n",
    "    pdf.multi_cell(w = 0, h = 5, txt = f\"PIMD: {IDs[article_number-1]}\", align = \"L\")\n",
    "\n",
    "    pdf.set_text_color(r = 0, g = 0, b = 0)\n",
    "    pdf.set_font('Roboto', style = 'B', size = 12)\n",
    "    pdf.multi_cell(w = 0, h = 5, txt = f\"{titles[article_number-1]}\")\n",
    "\n",
    "    pdf.ln(h = 2.5)\n",
    "\n",
    "    pdf.set_font('Roboto', style = '', size = 10)\n",
    "    pdf.multi_cell(w = 0, h = 5, txt = f\"{abstracts[article_number-1]}\")\n",
    "\n",
    "pdf.output('pubmed_articles.pdf')\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
